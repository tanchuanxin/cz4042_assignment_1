{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "\n",
    "This notebook shall answer assignment_1b question 1.\n",
    "\n",
    "# Table of Contents <a name=\"toc\"></a>\n",
    "\n",
    "* [Imports](#imports)\n",
    "* [Global](#global)\n",
    "* [Helper Functions](#helper_functions)\n",
    "* [Question 1: Convergence](#convergence)\n",
    "    * [Model Parameters](#model_parameters)\n",
    "    * [Create the Model](#create_the_model)\n",
    "    * [Run the Model](#run_the_model)\n",
    "    * [Save Data Objects](#save_data_objects)\n",
    "    * [Plot Model Performance](#plot_model_performance)\n",
    "    * [Comparing Models](#comparing_models)\n",
    "    * [Eyeballing Convergence](#eyeballing_convergence)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports <a name=\"imports\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "from tensorflow import keras\n",
    "from tqdm.keras import TqdmCallback\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/X_train.npy')\n",
    "X_test = np.load('data/X_test.npy')\n",
    "Y_train = np.load('data/Y_train.npy')\n",
    "Y_test = np.load('data/Y_test.npy')\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global <a name=\"global\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# data objects\n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions <a name=\"helper_functions\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_history_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_object(histories, model_name, history_object):    \n",
    "    plt.plot(histories[model_name][history_object], label='train_'+history_object)\n",
    "    plt.plot(histories[model_name]['val_'+history_object], label='val_'+history_object)\n",
    "    plt.ylabel(history_object)\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"center right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### histories_saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename like 'data/histories_q1.json'\n",
    "def histories_saver(histories, filename):\n",
    "    histories_json = {}\n",
    "    for key in histories.keys():\n",
    "        histories_json[key] = histories[key].history\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(histories_json, file)\n",
    "\n",
    "    print(\"Histories saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Convergence  <a name=\"convergence\"></a>\n",
    "[Back to top](#toc)\n",
    "\n",
    "<i>Design a 3-layer feedforward neural network consists of an input layer, a hidden-layer of 10 neurons having ReLU activation functions, and a linear output layer. Use mini-batch gradient descent with a batch size = 8, ùêø2 regularization at weight decay parameter ùõΩ = 10‚àí3 and a learning rate ùõº = 10‚àí3 to train the network.\n",
    "\n",
    "* a) Use the train dataset to train the model and plot both the train and test errors against epochs.\n",
    "* b) State the approximate number of epochs where the test error is minimum and use it to stop training.\n",
    "* c) Plot the predicted values and target values for any 50 test samples.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters <a name=\"model_parameters\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters set\n"
     ]
    }
   ],
   "source": [
    "num_neurons = 10\n",
    "\n",
    "weight_decay_parameter = 10e-3\n",
    "regularization = keras.regularizers.l2(weight_decay_parameter)\n",
    "\n",
    "optimizer = 'sgd'\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = ['mse']\n",
    "\n",
    "epochs = 5000\n",
    "learning_rate = 10e-3\n",
    "batch_size = 8\n",
    "\n",
    "# callbacks = [TqdmCallback(verbose=1)]\n",
    "# callbacks = [TqdmCallback(verbose=1), tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)]\n",
    "\n",
    "print(\"Model Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model <a name=\"create_the_model\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_neurons, regularization, optimizer, loss, metrics):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(num_neurons, activation='relu', kernel_regularizer=regularization, bias_regularizer=regularization),\n",
    "        keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=metrics)\n",
    "    \n",
    "    print(\"Model created\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model <a name=\"run_the_model\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80acda21b8849a89fde5c9fb04625b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506885ea6a2a4a13b902c642ce2268d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model(num_neurons, regularization, optimizer, loss, metrics)\n",
    "\n",
    "callbacks = [TqdmCallback(verbose=1)]\n",
    "model_name = 'convergence_test_1'\n",
    "\n",
    "histories[model_name] = model.fit(X_train, Y_train,\n",
    "                                        epochs=epochs,\n",
    "                                        verbose = 0,\n",
    "                                        batch_size=batch_size,\n",
    "                                        validation_data=(X_test, Y_test),\n",
    "                                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(num_neurons, regularization, optimizer, loss, metrics)\n",
    "\n",
    "callbacks = [TqdmCallback(verbose=1), tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)]\n",
    "model_name = 'convergence_test_2'\n",
    "\n",
    "histories[model_name] = model.fit(X_train, Y_train,\n",
    "                                        epochs=epochs,\n",
    "                                        verbose = 0,\n",
    "                                        batch_size=batch_size,\n",
    "                                        validation_data=(X_test, Y_test),\n",
    "                                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(num_neurons, regularization, optimizer, loss, metrics)\n",
    "\n",
    "callbacks = [TqdmCallback(verbose=1), tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)]\n",
    "model_name = 'convergence_test_3'\n",
    "\n",
    "histories[model_name] = model.fit(X_train, Y_train,\n",
    "                                        epochs=epochs,\n",
    "                                        verbose = 0,\n",
    "                                        batch_size=batch_size,\n",
    "                                        validation_data=(X_test, Y_test),\n",
    "                                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data Objects <a name=\"save_data_objects\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories_saver(histories, \"data/histories_q1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/histories_q1.json') as json_file:\n",
    "    histories = json.load(json_file)\n",
    "print('histories reloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Performance <a name=\"plot_model_performance\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'convergence_test_1'\n",
    "plot_history_object(histories, model_name, 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'convergence_test_2'\n",
    "plot_history_object(histories, model_name, 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'convergence_test_2'\n",
    "plot_history_object(histories, model_name, 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models <a name=\"comparing_models\"></a> \n",
    "[Back to top](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eyeballing Convergence <a name=\"eyeballing_convergence\"></a> \n",
    "[Back to top](#toc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cz4042_env",
   "language": "python",
   "name": "cz4042_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
